{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11205330,"sourceType":"datasetVersion","datasetId":6990112}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pymupdf python-docx langchain langchain_community chromadb faiss-gpu\nimport os\nimport fitz\nimport re\nimport faiss\nimport numpy as np\n\nfrom docx import Document\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import pipeline\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-03T07:50:59.065690Z","iopub.execute_input":"2025-04-03T07:50:59.066328Z","iopub.status.idle":"2025-04-03T07:50:59.074715Z","shell.execute_reply.started":"2025-04-03T07:50:59.066299Z","shell.execute_reply":"2025-04-03T07:50:59.073937Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/input-data-pdfs/Maple_plant_guide.txt\n/kaggle/input/input-data-pdfs/Jade_Bonsai_Care_guidelines.docx\n/kaggle/input/input-data-pdfs/attention.pdf\n/kaggle/input/input-data-pdfs/Fish_care.pdf\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Plan of Action and Project Over view\n\n### Project over view \n    - 1. user will have option to \"summarize\" the document and \"Chat\" with document\n    - 2. user will upload the appropriate document to work with\n    - 3. model will process the document according to the option selected\n\n### plan of action\n    - 1. read the documents (type of documents:- pdf(✔), docx(✔), txt(✔))\n         a. for pdf read it using pdfplumber(Unable to Install) or pyMuPDF(✔)\n         b. for txt read it directly as is it just strings(✔)\n         c. for docx use docx(✔)\n    - 2. Clean the documents (✔), Chunk the documnets (✔), Vectorize the documents(optional in case if we want our own vector Db)\n    - 3. initialize the models (Both summarizer (✔) and the another one which will be used for similarity search (✔))\n    - 4. Summarize the text - directly use invoke method to summarize the test(✔)\n    - 5. Chat \n         a. Perform Similarity search between the quey and chunks (✔)\n         b. Create Prompts of similar results of query and chunks of document (✔)\n         c. pass the prompts to a LLM to get Answer (✔)","metadata":{}},{"cell_type":"markdown","source":"### For PDF Files","metadata":{}},{"cell_type":"code","source":"# Extracting text from PDF's\ndef extract_pdf(file_path):\n    doc = fitz.open(file_path)\n    text = \"\"\n    for page in doc:\n        text += page.get_text()\n    return text\n\n# Cleaning the extracted text\ndef clean_text(text):\n     # Replace multiple newlines with a single newline (preserves paragraphs)\n    text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n    text = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", text)\n    text  = re.sub(r'[^\\x00-\\x7F]+', \" \", text) ## hyper links are highlighted as \"\\xa0\" so we will remove this\n    return text\n\n# making chunks of 1000 words with overlap of 500 words\ndef chunks_of_text(extracted_text):\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 200, chunk_overlap = 50)\n    chunks = text_splitter.split_text(extracted_text)\n    return chunks\n\n\ndef create_chunks(text, max_length = 1024):\n    chunks = [text[i:i+max_length] for i in range(0, len(text), max_length)]\n    return chunks","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"extracted_text = extract_pdf(\"/kaggle/input/input-data-pdfs/attention.pdf\")\n# cleaned_text_pdf = clean_text(extracted_text)\nchunks_pdf = create_chunks(extracted_text)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### For Docx files","metadata":{}},{"cell_type":"code","source":"def extract_doc(file):\n    doc = Document(file)\n    text = \"\\n\".join([data.text for data in doc.paragraphs])\n    return text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"extracted_text = extract_doc(\"/kaggle/input/input-data-pdfs/Jade_Bonsai_Care_guidelines.docx\")\ncleaned_text = clean_text(extracted_text)\nchunks = chunks_of_text(cleaned_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### For txt files","metadata":{}},{"cell_type":"code","source":"def extract_txt(file):\n    data = open(file,\"r\").read()\n    return data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"extracted_text = extract_txt(\"/kaggle/input/input-data-pdfs/Maple_plant_guide.txt\")\ncleaned_text = clean_text(extracted_text)\nchunks_txt = chunks_of_text(cleaned_text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Initializing the models Summarizer, Embedding, q_a","metadata":{}},{"cell_type":"code","source":"summarizer = pipeline(\"summarization\", model=\"google/pegasus-large\")\n# MBZUAI/LaMini-Flan-T5-248M :- another option\nembedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\nq_a_model = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def Langchain_pipeline(file, model):\n\n    # Check for the File Extension and excute the Read operation\n    ext = os.path.splitext(file)[1]\n    if ext == \".pdf\":\n        # Read PDF file\n        doc = fitz.open(file)\n        text = \"\"\n        for page in doc:\n            text += page.get_text()\n            \n    if ext == \".docx\":\n        # Read docs file\n        doc = Document(file)\n        text = \"\" \n        for data in doc.paragraphs:\n            text += data.text\n            \n    if ext == \".txt\":\n         # Read txt file\n        text = open(file,\"r\").read()\n    \n\n    # chunk the data \n    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 50)\n    chunks = text_splitter.split_text(text)\n    \n    # invoke the data\n    # Summarize each chunk separately (You can use list comprehension)\n    summaries = []\n    for chunk in chunks:\n        summary = model(chunk, max_length=100, min_length=50, do_sample=False)[0]['summary_text']\n        summaries.append(summary)\n\n    # Concatenate the summaries into a single string\n    summary = ' '.join(summaries)\n    return summary","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Langchain_pipeline(\"/kaggle/input/input-data-pdfs/Jade_Bonsai_Care_guidelines.docx\", summarizer)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Q and A with Document","metadata":{}},{"cell_type":"code","source":"# we will create chunks of the whole document\n# we will embedd all the chunks into vectors and store it in chromadb\n# we will embedd the query entered by the user \n# than perform the similarity search between the embeddings of query and documents and return the top 3 similarity search chunks\n# Than we will feed the usery query along with similar chunks to LLM to generate human like response","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# I/O operation","metadata":{}},{"cell_type":"code","source":"def extract_pdf(file_path):\n    doc = fitz.open(file_path)\n    text = \"\"\n    for page in doc:\n        text += page.get_text()\n    return text\n\ndata = extract_pdf(\"/kaggle/input/input-data-pdfs/attention.pdf\")\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,  chunk_overlap = 50)\nchunks = text_splitter.split_text(data)\n\n# Embbed the chunks\nchunks_embeddings = embedding_model.encode(chunks).astype(np.float32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# user Query and Embedding it\nuser_query = \"What are the two most commonly used attention function\"\nuser_query_embedding = embedding_model.encode(user_query)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# FAISS functions\ndef create_faiss_index(chunks_embeddings):\n    # chunks_embeddings_dimension :- 384 \n    chunks_embeddings_dimension = chunks_embeddings.shape[1]\n    # create Faiss index (L2 Distance)\n    index = faiss.IndexFlatL2(chunks_embeddings_dimension)\n    index.add(chunks_embeddings)\n\n    return index\n\ndef search_faiss(chunks, chunks_embeddings, user_query):\n    top_k = 3 \n    indices = create_faiss_index(chunks_embeddings)\n    similar_indexes = indices.search(user_query, top_k)[1]\n    similarity_results = [chunks[result] for result in similar_indexes[0]]\n    return similarity_results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"similar_queries = search_faiss(chunks= chunks, user_query = user_query_embedding.reshape(1,-1))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Designing the Prompt\ncontext = \" \".join(similarity_result)\nprompt = f\"Answer the Following Question and explain the concept in brief based on the given context:\\n\\nContext: {context} \\n\\nQuestion: {user_query} \\nAnswer:\"\nprint(prompt)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"result = q_a_pipeline(prompt, max_length =200)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Question: \",user_query)\nprint(\"Answer: \", result[0][\"generated_text\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# pdf pipeline\ndef extract_pdf(file_path):\n    doc = fitz.open(file_path)\n    text = \"\"\n    for page in doc:\n        text += page.get_text()\n    return text\n    \n# fully Pipeline\ndef Q_a_pipeline(embedding_model, user_query, chunks, q_a_model):\n    # Embbed the chunks\n    embedded_chunks = embedding_model.encode(chunks).astype(np.float32)\n    \n    # Embbed the user query\n    embedded_user_query = embedding_model.encode(user_query).astype(np.float32)\n    \n    # FAISS and Similarity Search\n    similar_queries = search_faiss(chunks= chunks, user_query = embedded_user_query.reshape(1,-1), chunks_embeddings = embedded_chunks)\n\n    # Designing the Prompt\n    context = \" \".join(similar_queries)\n    prompt = f\"Answer the Following Question and explain the concept in brief based on the given context:\\n\\nContext: {context} \\n\\nQuestion: {user_query}\"\n    \n    # Predict\n    final_answer = q_a_model(prompt, max_length = 500)[0][\"generated_text\"]\n    return final_answer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = extract_pdf(\"/kaggle/input/input-data-pdfs/Fish_care.pdf\")\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,  chunk_overlap = 50)\nchunks = text_splitter.split_text(data)\n\nuser_query = str(input(\"Enter the Query :- \"))\nQ_a_pipeline(embedding_model, user_query, chunks, q_a_model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}